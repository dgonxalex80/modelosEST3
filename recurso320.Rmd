---
title: <span style="color:#034a94"> **Estimación del modelo**</span>
author: "Modelos Estadísticos para la toma de decisiones"
output:
  html_document:
    code_folding: hide
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment = NA, warning = FALSE, message = FALSE)
# colores
c1="#FF7F00"
c2="#=EB0C6"
c3="#034A94"
c4="#686868"
color2=c(c1,c2)
library(memisc)
library(MASS)
library(lattice)
library(stats)
library(tidyverse)

# install.packages("learnr")          # solo una vez
# install.packages("devtools")     # solo una vez
# devtools::install_github("dgonxalex80/paqueteMOD", force = TRUE) #descarga paquete nivelatorioEST
set.seed(123) 
library(paqueteMOD)
data("dataMat")
dataMat = sample(dataMat, 1000, replace = TRUE)
glm(gana ~ nota , family = binomial(link = "logit"), data = dataMat) -> modelo1
summary(modelo1) 

data("matriculah")
matriculah = sample(matriculah, 1000, replace = TRUE)

```

</br></br>

```{r, echo=FALSE, out.width="100%", fig.align = "center"}
# knitr::include_graphics("img/puntos1.png")
```


</br></br>

Para realizar la estimación del modelo logit utilizamos la función `glm()`  

</br>


```{r, eval=FALSE}
library(tidyverse)
data("matriculah")
matriculah = sample(matriculah, 1000, replace = TRUE)  # se realiza un proceso bootstrap
matriculah %>% 
glm(honor ~ matematicas , family = binomial(link = "logit"), data = .) -> modelo1
summary(modelo1) 
```




<pre>
Call:
glm(formula = honor ~ matematicas, family = binomial(link = "logit"), 
    data = .)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.9618  -0.7065  -0.4140  -0.1652   2.5208  

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept) -9.04461    0.63678  -14.20   <2e-16 ***
matematicas  0.14415    0.01113   12.95   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1113.55  on 999  degrees of freedom
Residual deviance:  877.63  on 998  degrees of freedom
AIC: 881.63

Number of Fisher Scoring iterations: 5
</pre>


</br></br>

El modelo estimado en su forma original :

</br>

$$\ln \Bigg( \dfrac{\widehat{P_{i}}}{1-\widehat{P_{i}}} \Bigg) = \widehat{\beta_{0}} + \widehat{\beta_{1}} \hspace{.2cm}x_{i} = -9.04461  + 0.14415 \hspace{.2cm} x_{i}$$
</br></br>

Utilizamos la función inversa del logaritmo

</br>


$$\Bigg( \dfrac{\widehat{P_{i}}}{1-\widehat{P_{i}}} \Bigg) = \exp{\bigg\{ \widehat{\beta_{0}} + \widehat{\beta_{1}} \hspace{.2cm} x_{i}}\bigg\}$$
</br></br>


En caso de ser $P_{i} = 0.80$, entonces $1-P_{i} = 0.20$, luego :

</br>

$$\Bigg( \dfrac{0.80}{0.20} \Bigg) = 4.0 $$

Indicando una razón entre las probabilidades de 4 a 1.  Es cuatro veces mas problable que ocurra el evento sobre que no ocurra.


En el modelo estimado esta relación para un valor específico de $X$ de la siguiente forma:

</br>

$$\Bigg( \dfrac{\widehat{P_{i}}}{1-\widehat{P_{i}}} \Bigg) = \exp{\big\{ -9.04461  + 0.14415 \hspace{.2cm}x_{i}}\big\}$$
</br></br>


Un estudiante con un puntaje de en matemáticas de $60$ tendrá una razón $Odds$ de :

</br>

$$\Bigg( \dfrac{\widehat{P_{i}}}{1-\widehat{P_{i}}} \Bigg) = \exp{\big\{ -9.04461  + 0.14415 \hspace{.2cm} \times 70}\big\} = 2.84593$$

Lo que indica que un estudiante con puntaje en matemáticas igual a 70, tiene 2.85 veces más probabilidad de obtener la matricula de honor en comparación de no tenerla.

</br></br>




## <span style="color:#034A94">**Pruebas de significancia individual**</span>

</br>


En este caso la significancia del modelo se determina por los valores del estadístico **Wald chi-square**, bajo la condición  el tamaño de la muestra grande. 

$H_0 : \beta_{i} = 0$
$H_1 : \beta_{i} \neq 0$

Estadístico de prueba

$$W_{i} = \dfrac{\widehat{\beta}_{i}}{\sigma^2_{\beta_{i}}} \sim N(0,1) $$


<pre>
Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept) -9.04461    0.63678  -14.20   <2e-16 ***
matematicas  0.14415    0.01113   12.95   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</pre>

</br>


En el ejemplo ambos coeficientes son estadisticamente significativos, con valor p de cero

</br></br>

## <span style="color:#034A94">**Interpretación de los coeficientes**</span>

</br>

### <span style="color:#034A94">$\beta_{0}$</span>

</br>

El coeficiente estimado $\widehat{\beta}_{0}$ corresponde al valor esperado del logaritmo de la razón de probabilidades para un estudiante con nota cero en matemáticas.  Para leerlo en términos de razón de probabilidades realizamos la siguiente transformación:

</br>

```{r, echo=FALSE}
# coeficientes estimados
b=modelo1$coefficients
b0=b[1]; names(b0)= " "
b1=b[2]; names(b1)= " "
#-------------------------
x=0
# exp(b0+b1*x)
# exp(b0+b1*x)/(1-exp(b0+b1*x))

cat("exp{b0} = exp{-9.04461} = ", exp(-9.04461))
```
</br>

Cuando $x=0$ el valor de la razón de probabilidades es de $0.0001180255$, indicando que la probabilidad $(1-P_{i})$ es mucho mas grande que $P_{i}$ . Lo cual es consecuente, dado que obtener una nota de $x=0$, estima una probabilidad de ganar la asignatura casi nula.

</br></br>

### <span style="color:#034A94">$\beta_{1}$</span>

</br>

Ahora para interpretar el aporte que genera un punto adicional en la nota de matemáticas sobre la probabilidad realizamos el siguiente cálculo:

</br>

<!-- $$\exp{\{ 0.1563404 \}} = 1.169224$$ -->




</br></br>

$\widehat{\beta}_{1}$ indica el cambio en $ln(p/(1-p))$  debido a un incremento unitario en $x$,   por lo que es necesario sacar la función inversa al logaritmo que es la función exponencial (`exp()`)

Por cada unidad de aumento de $x$ los $odds$ de obtener matricula se  incrementan en : $1.16$ unidades


```{r, echo=FALSE}
cat("exp(b1) = exp(0.14415) = ", exp(0.14415) )
```



</br>

Un intervalo de confianza para los coeficientes se puede obtener mediante :

</br>
```{r, message=FALSE}
library(MASS)
confint(object = modelo1, level = 0.95 )
```
</br></br>

## <span style="color:#034A94">**Significancia del modelo**</span>

</br>

En este caso se plantean las hipótesis :

</br>


$$H_{0} : \beta_{1} = \beta_{2} = \dots \beta_{k} =0 \hspace{1cm}$$
$$H_{a} : \text{Algún } \beta_{i} \text{ es diferente de }  0$$

</br>

El equivalente de la prueba global de significancia del modelo logit tiene como estadístico de prueba la chi-cuadrado que se obtiene restando la suma desviaciones del modelo nulo con la suma de las desviaciones de los residuales que se presentan en el resumen del modelo

</br>

<pre>
    Null deviance: 1113.55  on 999  degrees of freedom
Residual deviance:  877.63  on 998  degrees of freedom
AIC: 881.63
</pre>

$$
X^2 = \text{ Null deviance} - \text{ Residual deviance} = 1113.55 - 877.63 = 235.92
$$
```{r}
with(modelo1, null.deviance - deviance )
```

</br>

Que tiene una distribución $\chi^2 _{v: gl_{null} -gl_{residual}}$

```{r}
with(modelo1, pchisq(null.deviance - deviance , df.null-df.residual, lower.tail = FALSE))
```

</br>

Lo cual indica que se rechaza $H_0$, en favor de $H_a$, el modelo es significativo


</br>

<div class="content-box-gray">
### <span style="color:#686868">**Nota:**</span> 

</br>

Es importante examinar la significancia de los coeficientes estimados obtenidos mediante el metodo de máxima verosimilitud.  En este caso en lugar de calcular el valor p para cada coeficiente, se utiliza el estadístico **Z** de la prueba  **chi-cuadrado de Wald**

* En este tipo de modelos la bondad de ajuste pasa a un segundo plano y cobra importancia el signo de los coeficientes y su significancia estadística.

* Tambien es condición que las observaciones deben ser independientes unas de otras

* Y la relación entre $\ln(Odds)$  y las variables independientes $X_{1},\dots, X_{k} + \varepsilon$ debe ser lineal

* Finalmente para convertir el valor estimado de probabilidad en una categoría se debe encontrar el valor de un punto de corte a partir del cual se considera que la variable $Y$ pertenece a una categoría. En caso de que este valor fuese p=0.5 ($P(Y=1|X) > 0.50$), entonce si la estimación del modelo arroja un valor en el rango (0.50 - 1.0), se le asignará el valor de $1$, en caso contrario tomará el valor de $0$.

</div>

