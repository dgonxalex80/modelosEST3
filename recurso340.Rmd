---
title: <span style="color:#034a94"> **Validación cruzada**</span>
author: "Modelos Estadísticos para la toma de decisiones"
output: html_document
css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment = NA, warning = FALSE, message = FALSE)
# colores
c1="#FF7F00"
c2="#=EB0C6"
c3="#034A94"
c4="#686868"
color2=c(c1,c2)
library(memisc)
library(MASS)
library(lattice)
library(stats)
# install.packages("learnr")          # solo una vez
# install.packages("devtools")     # solo una vez
# devtools::install_github("dgonxalex80/paqueteMOD", force = TRUE) #descarga paquete nivelatorioEST
library(paqueteMOD)
data("dataMat")
dataMat = sample(dataMat, 1000, replace = TRUE)
glm(gana ~ nota , family = binomial(link = "logit"), data = dataMat) -> modelo1
summary(modelo1) 
```

</br></br>

La validación cruzada es una metodología empleada para determinar si los resultados obtenidos es consistente para muestras diferentes a la muestra con que se estima el modelo

Para realizarlo se parte la muestra en dos submuestras:

* muestra de entrenamiento
* muestra de prueba

Una vez separadas las muestras se estima el modelo con la muestra de entrenamiento (modelo1) para después probar la capacidad de clasificación del modelo.


El siguiente ejemplo ilustra su construcción y explicación.


### **Ejemplo**

La data dataMat contiene **notas** de un examen de admisión y el resultado de de aprobación o no del resultado al finalizar el primer curso de matemáticas fundamentales para primer semestre de universidad (**Gana** o **Pierde**), que contiene el resultado obtenido por $n = 200$ estudiantes.


</br></br>

```{r}
head(dataMat)

```


Con esta información se pretende construir un modelo que permita la predicción del riesgo de perder el curso conociendo el resultado de la prueba de admisión


$$
\text{gana} \hspace{.2cm}= \hspace{.2cm} \beta_{0} + \beta_{1} \hspace{.2cm} \text{nota} \hspace{.3cm}+ \hspace{.2cm}\varepsilon
$$
Inicialmente se divide la muestra en dos partes, una para realizar el entrenamiento del modelo y una segunda para realiza la prueba de los resultados


```{r}
names(dataMat)
nrow(dataMat)

ntrain <- nrow(dataMat)*0.6
ntest <- nrow(dataMat)*0.4
c(ntrain,ntest)

set.seed(123)
index_train<-sample(1:nrow(dataMat),size = ntrain)
train<-dataMat[index_train,]  # muestra de entrenamiento
test<-dataMat[-index_train,]  # muestra de prueba

```


Con la muestra de entrenamiento se estima el modelo

```{r}
modelo1 <- glm(gana~ nota,data = train,family = "binomial")
summary(modelo1)
```

Se utiliza la muestra de prueba para encontrar la estimación de las probabilidades para sus valores

```{r}
library(tidyverse)
valor_pronosticado <- predict(modelo1,test,type = "response")
niveles_pronosticados <- ifelse(valor_pronosticado >0.5, "Si","No") %>% 
                             factor(.)

rendimiento_data<-data.frame(observados=test$gana,
                             predicciones= niveles_pronosticados)

Positivos <- sum(rendimiento_data$observados=="Si")
Negativos <- sum(rendimiento_data$observados=="No")
Positivos_pronosticados <- sum(rendimiento_data$predicciones=="Si")
Negativos_pronosticados <- sum(rendimiento_data$predicciones=="No")
Total <- nrow(rendimiento_data)
VP<-sum(rendimiento_data$observados=="Si" & rendimiento_data$predicciones=="Si")
VN<-sum(rendimiento_data$observados=="No" & rendimiento_data$predicciones=="No")
FP<-sum(rendimiento_data$observados=="No" & rendimiento_data$predicciones=="Si")
FN<-sum(rendimiento_data$observados=="Si" & rendimiento_data$predicciones=="No")

matriz_confusion=matrix(c(VN, FN, FP,VP), nrow=2)

rownames(matriz_confusion) = c(" No ", " Si    ")
colnames(matriz_confusion) = c("No", "Si")
matriz_confusion
```



```{r}
Exactitud <- (VP+VN)/Total
Tasa_de_Error <- (FP+FN)/Total
Sensibilidad <- VP/Positivos
Especificidad <- VN/Negativos
Precision <- VP/Positivos_pronosticados
Valor_prediccion_negativo <- VN / Negativos_pronosticados

indicadores <- t(data.frame(Exactitud,Tasa_de_Error,Sensibilidad,Especificidad,Precision,Valor_prediccion_negativo))
indicadores

```

### **Curva ROC**



```{r}
library(pROC)
curva_ROC <- roc(test$gana, valor_pronosticado)
auc<- round(auc(curva_ROC, levels =c(0,1), direction = "<"),4) # 0.9177


ggroc(curva_ROC, colour = "#FF7F00", size=2)+
ggtitle(paste0("Curva ROC ", "(AUC = ", auc, ")"))+
xlab("Especificidad")+
ylab("Sensibilidad")  
```



  