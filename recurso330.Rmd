---
title: <span style="color:#034a94"> **Evaluación del modelo**</span>
author: "Modelos Estadísticos para la toma de decisiones"
output: html_document
css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment = NA, warning = FALSE, message = FALSE)
# colores
c1="#FF7F00"
c2="#=EB0C6"
c3="#034A94"
c4="#686868"
color2=c(c1,c2)
library(memisc)
library(MASS)
library(lattice)
library(stats)
library(tidyverse)

# install.packages("learnr")          # solo una vez
# install.packages("devtools")     # solo una vez
# devtools::install_github("dgonxalex80/paqueteMOD", force = TRUE) #descarga paquete nivelatorioEST
library(paqueteMOD)
library(tidyverse)
data(matricular)
matricular %>% 
  glm(matricula ~ matematicas , family = binomial(link = "logit"), data = .) -> modelo1
summary(modelo1) 
```

 </br></br>

## <span style="color:#034A94">**Bondad de ajuste del modelo**</span>

</br>

Para determinar la bondad de ajuste del modelo se utiliza el resultado de la probabilidad que estima el modelo y se asigna un valor de cero para los individuos que tengan valores menores o iguales a un punto $c$, que en este caso tomamos como $0.50$. Para valores mayores a $0.5$ se asigna un valor de $1$. Al construir una tabla con los resultados de la predicción contra los valores reales de $Y$, obtenemos:

</br>

<pre>
        |                predicción    |  
        |         |   0     |    1     |
--------|---------|---------|----------|   
Estado  |  0      |     140 |      11  |
real    |  1      |      27 |      22  |

</pre>

</br>

Representados por el siguiente gráfico de mosaico:

</br>


```{r}
library(vcd)
predicciones <- ifelse(test = modelo1$fitted.values > 0.5, yes = 1, no = 0)
mc <- table(modelo1$model$matricula, predicciones,
                          dnn = c("Estado real", "Predicciones"))
mosaic(mc, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("#11224D", "#F98125", "#F5B841","#2C599D"), 2, 2)))
```

</br>

Los colores azules representan la proporción de clasificaciones correcta :

* Siendo $0$, lo clasifica como $0$ y 
* Siendo $1$ lo clasifica como $1$

Los colores naranjas corresponden a las proporciones de clasificaciones erradas por el modelo.

* Falsos positivos
* Falsos negativos

La proporción de clasificaciones correctas dan una aproximación del valor $R^2$

</br>

$$ 
\dfrac{140+22}{140+27+11+22} = \dfrac{162}{200} = 0.81
$$
Este valor cuenta como el $R^2$ , es decir que el modelo explica (clasifica de manera adecuada) el 81% de los casos

</br></br>


Este valor se puede obtener de la matriz de confusión 


## <span style="color:#034A94">**Matriz de confusión**</span>

```{r, eval=FALSE}
library(paqueteMOD)
data("matricular")
modelo1= glm(matricula ~ matematicas, data=matricular, family = "binomial")
# summary(modelo1)
matricula.fit = as.numeric(modelo1$fitted.values>0.5)  # clasificacion de las estimaciones en 0,1
data1= data.frame(matricular$matricula, matricula.fit)
matrizC=table(data1)
matrizC   # matriz de confusión
```

<pre>
        |                predicción    |  
        |         |   0     |    1     |
--------|---------|---------|----------|   
Estado  |  0      |     140 |      11  |
real    |  1      |      27 |      22  |

</pre>


</br>

>

A partir de la matriz de confusión se obtienen indicadores 

#### <span style="color:#034a94">**Capacidad de clasificación del modelo**</span>

En una de las características más importantes del modelo, pues permite valorar a través de la matriz de confusión las clasificaciones correctas por medio de las predicciones del modelo. 

Existen adicionamente otros indicadores que pueden ser utilizados como es el estadistico c asociado a la curva ROC (Trvrivrt Oprtsyong Charasteristic) . Esta curva compara diferentes puntos de corte de la probabilidad que permite establecer la tasa de clasificaciones correcta de verdaderos positivos y de falsos positivos:

</br></br>

### **Exactitud**

Porcentaje de casos correctamente clasificados

$$


$$


### **Sensibilidad**

Porcentaje de positivos que son clasificados por el modelo como positivos 

$$
TPR = \dfrac{\text{número de positivos correctamente pronosticados}}{\text{número de positivos reales totales}} = 
$$

### **Especificidad**

Porcentaje de negativos que son clasificados por el modelo como negativos 

$$
FPR = \dfrac{\text{número de falsos positivos}}{\text{número de negativos reales totales}}
$$

### **Falsos positivos**

Porcentaje de negativos, clasificados por el modelo como positivos



### **Falsos negarativos**

Porcentaje de positivos clasificados por el modelo como negativos


</br></br>

<div class="content-box-yellow">
### <span style="color:#686868">**Nota:**</span> 

Es importante examinar la significancia de los coeficientes estimados obtenidos mediante el metodo de máxima verosimilitud.  En este caso en lugar de calcular el valor p para cada coeficiente, se utiliza el estadístico **Z** de la prueba  **chi-cuadrado de Wald**

* En este tipo de modelos la bondad de ajuste pasa a un segundo plano y cobra importancia el signo de los coeficientes y su significancia estadística.

* Tambien es condición que las observaciones deben ser independientes unas de otras

* Y la relación entre $\ln(Odds)$  y las variables independientes $X_{1},\dots, X_{k} + \varepsilon$ debe ser lineal

* Finalmente para convertir el valor estimado de probabilidad en una categoría se debe encontrar el valor de un punto de corte a partir del cual se considera que la variable $Y$ pertenece a una categoría. En caso de que este valor fuese p=0.5 ($P(Y=1|X) > 0.50$), entonce si la estimación del modelo arroja un valor en el rango (0.50 - 1.0), se le asignará el valor de $1$, en caso contrario tomará el valor de $0$.

</div>



</br></br>
