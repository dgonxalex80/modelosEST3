---
title: <span style="color:#034a94"> **Evaluación del modelo**</span>
author: "Modelos Estadísticos para la toma de decisiones"
output: html_document
css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment = NA, warning = FALSE, message = FALSE)
# colores
c1="#FF7F00"
c2="#=EB0C6"
c3="#034A94"
c4="#686868"
color2=c(c1,c2)
library(memisc)
library(MASS)
library(lattice)
library(stats)
library(tidyverse)

# install.packages("learnr")          # solo una vez
# install.packages("devtools")     # solo una vez
#devtools::install_github("dgonxalex80/paqueteMOD", force = TRUE) #descarga paquete nivelatorioEST
library(paqueteMOD)
data("dataMat")
dataMat = sample(dataMat, 1000, replace = TRUE)
glm(gana ~ nota , family = binomial(link = "logit"), data = dataMat) -> modelo1
summary(modelo1) 
```

 </br></br>

## <span style="color:#034A94">**Bondad de ajuste del modelo**</span>

</br>

Para determinar la bondad de ajuste del modelo se utiliza el resultado de la probabilidad que estima el modelo y se asigna un valor de cero para los individuos que tengan valores menores o iguales a un punto $c$, que en este caso tomamos como $0.50$. Para valores mayores a $0.5$ se asigna un valor de $1$. Al construir una tabla con los resultados de la predicción contra los valores reales de $Y$, obtenemos:

</br>


<pre>
        |                predicción    |  
        |         |   No    |    Si    |
--------|---------|---------|----------|   
Estado  |  No     |     723 |      37  |
real    |  Si     |      53 |     187  |

</pre>

</br></br>

Representados por el siguiente gráfico de mosaico:

</br>


```{r, echo=FALSE}
library(vcd)
predicciones <- ifelse(test = modelo1$fitted.values > 0.5, "Si" , "No")
mc <- table(modelo1$model$gana, predicciones,
                          dnn = c("Estado real", "Predicciones"))
mosaic(mc, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("#11224D", "#F98125", "#F5B841","#2C599D"), 2, 2)))
```

</br></br>

Los colores azules representan la proporción de clasificaciones correcta :

</br>

* Siendo $No$, lo clasifica como $No$ : **VN** 

* Siendo $Si$ lo clasifica como $Si$  : **VP**

</br>

Los colores naranjas corresponden a las proporciones de clasificaciones erradas por el modelo.

* Siendo $Si$, lo clasifica incorrectamente como $No$ :  Falsos Negativo : **FN**  

* Siendo $No$, lo  clasifica incorrectamente como $Si$ : Falso Positovo  : **FP**

</br></br>

La proporción de clasificaciones correctas dan una aproximación del valor $R^2$

</br>

$$ 
\dfrac{723+187}{723+53+37+187} = \dfrac{910}{1000} = 0.910
$$
Este valor cuenta como el $R^2$ , es decir que el modelo explica (clasifica de manera adecuada) el 91% de los casos.

</br></br>


Este valor se puede obtener de la matriz de confusión 

</br></br>

## <span style="color:#034A94">**Matriz de confusión**</span>

</br>

Consiste en un método de evaluación del modelo estimado, mediante la separación de la data en dos partes. Una primera para estimar el modelo (train) que puede corresponder entre el 60% y el 80% de los datos y el restante porcentaje para una muestra con la que se evalúa el poder de predicción del modelo (Test)

Lo primero será estimar el modelo con la data.train y posteriormente valuar el modelo utilizando la data.test

Con los resulados obtenidos por la predicción del modelo sobre la muestra.test se construye la matriz de confisión que tiene la siguiente forma:

</br></br>

```{r, echo=FALSE, out.width="80%", fig.align = "center"}
knitr::include_graphics("img/matriz_confusion.png")
```


</br></br>


```{r, echo=FALSE}
# names(dataMat)
# nrow(dataMat)

ntrain <- nrow(dataMat)*0.6
ntest <- nrow(dataMat)*0.4
c(ntrain,ntest)

set.seed(123)
index_train<-sample(1:nrow(dataMat),size = ntrain)
train<-dataMat[index_train,]  # muestra de entrenamiento
test<-dataMat[-index_train,]  # muestra de prueba
```

</br></br>

```{r}
library(tidyverse)
valor_pronosticado <- predict(modelo1,test,type = "response")
niveles_pronosticados <- ifelse(valor_pronosticado >0.5, "Si","No") %>%
                             factor(.)

rendimiento_data<-data.frame(observados=test$gana,
                             predicciones= niveles_pronosticados)

Positivos <- sum(rendimiento_data$observados=="Si")
Negativos <- sum(rendimiento_data$observados=="No")
Positivos_pronosticados <- sum(rendimiento_data$predicciones=="Si")
Negativos_pronosticados <- sum(rendimiento_data$predicciones=="No")
Total <- nrow(rendimiento_data)
VP<-sum(rendimiento_data$observados=="Si" & rendimiento_data$predicciones=="Si")
VN<-sum(rendimiento_data$observados=="No" & rendimiento_data$predicciones=="No")
FP<-sum(rendimiento_data$observados=="No" & rendimiento_data$predicciones=="Si")
FN<-sum(rendimiento_data$observados=="Si" & rendimiento_data$predicciones=="No")

matriz_confusion=matrix(c(VP, FP, FN,VN), nrow=2)

rownames(matriz_confusion) = c(" No ", " Si    ")
colnames(matriz_confusion) = c("No", "Si")
# matriz_confusion
```


</br></br>

<pre>
        |                predicción             |  
        |         |   Si       |    No          |
--------|---------|------------|----------------|   
Estado  |  Si     |   81  (VP) |     22   (FN)  |
real    |  No     |   13  (FP) |     284  (VN)  |
</pre>


</br>

>

A partir de la matriz de confusión se obtienen indicadores 

</br></br>

#### <span style="color:#034a94">**Capacidad de clasificación del modelo**</span>

</br>

En una de las características más importantes del modelo, pues permite valorar a través de la matriz de confusión las clasificaciones correctas por medio de las predicciones del modelo. 

Existen adicionamente otros indicadores que pueden ser utilizados como es el estadistico c asociado a la curva ROC (Trvrivrt Oprtsyong Charasteristic) . Esta curva compara diferentes puntos de corte de la probabilidad que permite establecer la tasa de clasificaciones correcta de verdaderos positivos y de falsos positivos:

</br></br>


### **Exactitud**

Porcentaje de casos correctamente clasificados

<div class="content-box-blue">
$$
\text{Exactitud} = \dfrac{\text{aciertos en clasificación}}{\text{Total}} = \dfrac{VP + VN}{\text{Total}} = \dfrac{81+281}{400} = 0.905
$$
</div>

</br></br>

### **Sensibilidad**

Porcentaje de positivos que son clasificados por el modelo como positivos 

<div class="content-box-blue">
$$
\text{Sensibilidad} = \dfrac{VP}{\text{Total positivos}} = \dfrac{81}{103} = 0.786
$$
</div>
</br></br>

### **Especificidad**

Porcentaje de negativos que son clasificados por el modelo como negativos 

<div class="content-box-blue">
$$
\text{Especificidad} = \dfrac{\text{VN}}{\text{Total negativos}} = \dfrac{284}{297} = 0.956
$$
</div>

</br></br>

### **Presición** 

Porcentaje de positivos pronosticados de manera correcta


<div class="content-box-blue">
$$
\text{Precision} = \dfrac{\text{VP}}{\text{Total clasificados positivos}} = \dfrac{81}{94} = 0.862 
$$ 
</div>

</br></br>

### **Valor de predicción negativo** 

Porcentaje de negativos clasificados por el modelo como negativos


<div class="content-box-blue">
$$
\text{Valor de prediccion negativo} = \dfrac{\text{VN}}{\text{Total clasificados negativos}} = \dfrac{284}{306} = 0.928 
$$ 
</div>

</br></br>


#### **Resumen**

</br>

```{r, eval=FALSE}
library(tidyverse)
Exactitud <- (VP+VN)/Total
Tasa_de_Error <- (FP+FN)/Total
Sensibilidad <- VP/Positivos
Especificidad <- VN/Negativos
Precision <- VP/Positivos_pronosticados
Valor_prediccion_negativo <- VN / Negativos_pronosticados

indicadores <- t(data.frame(Exactitud,Tasa_de_Error,Sensibilidad,Especificidad,Precision,Valor_prediccion_negativo))
indicadores %>% 
  round(.,3)
```
<pre>
                           
Exactitud                  0.912

Tasa de Error              0.088

Sensibilidad               0.786

Especificidad              0.956

Precisión                  0.862

Valor predicción negativo  0.928

</pre>

</br></br>

<div class="content-box-yellow">
### <span style="color:#686868">**Nota:**</span> 

Es importante examinar la significancia de los coeficientes estimados obtenidos mediante el metodo de máxima verosimilitud.  En este caso en lugar de calcular el valor p para cada coeficiente, se utiliza el estadístico **Z** de la prueba  **chi-cuadrado de Wald**

* En este tipo de modelos la bondad de ajuste pasa a un segundo plano y cobra importancia el signo de los coeficientes y su significancia estadística.

* Tambien es condición que las observaciones deben ser independientes unas de otras

* Y la relación entre $\ln(Odds)$  y las variables independientes $X_{1},\dots, X_{k} + \varepsilon$ debe ser lineal

* Finalmente para convertir el valor estimado de probabilidad en una categoría se debe encontrar el valor de un punto de corte a partir del cual se considera que la variable $Y$ pertenece a una categoría. En caso de que este valor fuese p=0.5 ($P(Y=1|X) > 0.50$), entonce si la estimación del modelo arroja un valor en el rango (0.50 - 1.0), se le asignará el valor de $1$, en caso contrario tomará el valor de $0$.

</div>



</br></br>
